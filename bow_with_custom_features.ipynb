{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7902ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "df = pd.read_csv('asset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df.sample(30000,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a12170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribution of duplicate and non-duplicate questions\n",
    "\n",
    "print(new_df['is_duplicate'].value_counts())\n",
    "print((new_df['is_duplicate'].value_counts()/new_df['is_duplicate'].count())*100)\n",
    "new_df['is_duplicate'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d72304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Repeated questions\n",
    "\n",
    "qid = pd.Series(new_df['qid1'].tolist() + new_df['qid2'].tolist())\n",
    "print('Number of unique questions',np.unique(qid).shape[0])\n",
    "x = qid.value_counts()>1\n",
    "print('Number of questions getting repeated',x[x].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dcc6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Repeated questions histogram\n",
    "\n",
    "plt.hist(qid.value_counts().values,bins=160)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "\n",
    "new_df['q1_len']=new_df['question1'].str.len()\n",
    "new_df['q2_len']=new_df['question2'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42607941",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88322060",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['q1_num_words'] = new_df['question1'].apply(lambda row: len(row.split(\" \")))\n",
    "new_df['q2_num_words'] = new_df['question2'].apply(lambda row: len(row.split(\" \")))\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_words(row):\n",
    "    w1=set(map(lambda word: word.lower().strip(),row['question1'].split(\" \")))\n",
    "    w2=set(map(lambda x:x.lower().strip(),row['question2'].split(\" \")))\n",
    "    return len(w1 & w2) # taking their intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9447af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_df['word_common'] = new_df.apply(common_words, axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0cb334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return (len(w1) + len(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888343bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['total_words']=new_df.apply(total_words,axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['word_share'] = round(new_df['word_common']/new_df['total_words'],2)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a230ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of features\n",
    "sns.displot(new_df['q1_len'])\n",
    "print('minimum characters',new_df['q1_len'].min())\n",
    "print('maximum characters',new_df['q1_len'].max())\n",
    "print('average num of characters',int(new_df['q1_len'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa722241",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(new_df['q2_len'])\n",
    "print('minimum characters',new_df['q2_len'].min())\n",
    "print('maximum characters',new_df['q2_len'].max())\n",
    "print('average num of characters',int(new_df['q2_len'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1633613",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(new_df['q1_num_words'])\n",
    "print('minimum words',new_df['q1_num_words'].min())\n",
    "print('maximum words',new_df['q1_num_words'].max())\n",
    "print('average num of words',int(new_df['q1_num_words'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd640bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(new_df['q2_num_words'])\n",
    "print('minimum words',new_df['q2_num_words'].min())\n",
    "print('maximum words',new_df['q2_num_words'].max())\n",
    "print('average num of words',int(new_df['q2_num_words'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff379f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# common words\n",
    "sns.distplot(new_df[new_df['is_duplicate'] == 0]['word_common'],label='non duplicate')\n",
    "sns.distplot(new_df[new_df['is_duplicate'] == 1]['word_common'],label='duplicate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8481f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# total words\n",
    "sns.distplot(new_df[new_df['is_duplicate'] == 0]['total_words'],label='non duplicate')\n",
    "sns.distplot(new_df[new_df['is_duplicate'] == 1]['total_words'],label='duplicate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## agar q1 and q2 me 4 se kam words hai to duplicaate hone ka prob kam hai\n",
    "# and agar 4 se jada words hai to duplicate hone ka probablity jada hai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a1dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# word share\n",
    "sns.distplot(new_df[new_df['is_duplicate'] == 0]['word_share'],label='non duplicate')\n",
    "sns.distplot(new_df[new_df['is_duplicate'] == 1]['word_share'],label='duplicate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# if wordshare >0.2 then duplicate hone ka chance jada hai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d459a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df = new_df.drop(columns=['id','qid1','qid2','question1','question2'])\n",
    "print(final_df.shape)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da4075da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# merge texts\n",
    "questions = list(new_df['question1']) + list(new_df['question2'])\n",
    "\n",
    "cv = CountVectorizer(max_features=3000)\n",
    "q1_arr, q2_arr = np.vsplit(cv.fit_transform(questions).toarray(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31137f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 6000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "temp_df1 = pd.DataFrame(q1_arr, index= new_df.index)\n",
    "temp_df2 = pd.DataFrame(q2_arr, index= new_df.index)\n",
    "temp_df = pd.concat([temp_df1, temp_df2], axis=1)\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "232e3e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 6008)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>total_words</th>\n",
       "      <th>word_share</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>2990</th>\n",
       "      <th>2991</th>\n",
       "      <th>2992</th>\n",
       "      <th>2993</th>\n",
       "      <th>2994</th>\n",
       "      <th>2995</th>\n",
       "      <th>2996</th>\n",
       "      <th>2997</th>\n",
       "      <th>2998</th>\n",
       "      <th>2999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398782</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115086</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327711</th>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>120</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367788</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>146</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151235</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_duplicate  q1_len  q2_len  q1_num_words  q2_num_words  word_common  \\\n",
       "398782             1      76      77            12            12           11   \n",
       "115086             0      49      57            12            15            7   \n",
       "327711             0     105     120            25            17            2   \n",
       "367788             0      59     146            12            30            0   \n",
       "151235             0      35      50             5             9            3   \n",
       "\n",
       "        total_words  word_share  0  1  ...  2990  2991  2992  2993  2994  \\\n",
       "398782           24        0.46  0  0  ...     0     0     0     0     0   \n",
       "115086           23        0.30  0  0  ...     0     0     0     0     0   \n",
       "327711           34        0.06  0  0  ...     0     0     0     0     0   \n",
       "367788           32        0.00  0  0  ...     0     0     0     1     0   \n",
       "151235           13        0.23  0  0  ...     0     0     0     0     0   \n",
       "\n",
       "        2995  2996  2997  2998  2999  \n",
       "398782     0     0     0     0     0  \n",
       "115086     0     0     0     0     0  \n",
       "327711     0     0     0     0     0  \n",
       "367788     0     0     0     0     0  \n",
       "151235     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 6008 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([final_df, temp_df], axis=1)\n",
    "print(final_df.shape)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc6c4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be563ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7721666666666667"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e42a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scrap",
   "language": "python",
   "name": "web_scrap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
